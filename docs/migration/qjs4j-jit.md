# qjs4j JIT Compilation: Technical Evaluation and Implementation Plan

## Executive Summary

Adding JIT compilation to qjs4j — translating qjs4j bytecode to JVM bytecode and loading it via `ClassLoader.defineClass()` — is **feasible and architecturally sound**. The qjs4j VM is a well-structured stack machine with 262 opcodes, clean metadata (local counts, constant pools, atom pools), and deterministic instruction encoding. The JVM's own HotSpot JIT compiler would then optimize the generated bytecode further into native machine code, yielding a two-tier compilation pipeline: qjs4j bytecode → JVM bytecode → native code.

The primary challenge is not bytecode translation itself, but **bridging JavaScript's dynamic semantics** (polymorphic types, prototype chains, Proxy traps, eval) with the JVM's statically-typed bytecode model. A practical approach is a **method-at-a-time baseline JIT** that emits generic helper calls, followed by optional **type-specializing optimizations** with inline caches and on-stack replacement (OSR).

A **global JIT enable/disable flag** on `JSRuntime` allows the entire JIT subsystem to be bypassed, forcing all execution through the interpreter. This is essential for debugging, differential testing, and isolating JIT-related bugs from interpreter bugs.

---

## 1. Architecture Assessment

### 1.1 Current VM Design

The qjs4j VM (`VirtualMachine.java`, ~3,464 lines) is a classic **switch-dispatch bytecode interpreter**:

```
JavaScript source
    → Parser/Lexer (compiler/)
    → AST
    → BytecodeCompiler/BytecodeEmitter
    → Bytecode (byte[] instructions + JSValue[] constantPool + String[] atomPool)
    → VirtualMachine.execute() switch-dispatch loop
```

Key characteristics:

| Property | Value |
|---|---|
| Opcodes | 262 (144 core + 118 extended from QuickJS) |
| Instruction encoding | Variable-length: 1–5 bytes (opcode + 0–4 byte operands) |
| Extended opcodes (≥256) | 2-byte encoding: `[0x00, payload]` where `payload = opcode - 256` |
| Stack model | `CallStack` with fixed 1024-element `JSStackValue[]` array |
| Stack values | Polymorphic `JSValue` references (sealed hierarchy: JSNumber, JSString, JSObject, ...) |
| Locals/args | Separate `JSValue[]` arrays per `StackFrame` |
| Closures | `JSValue[] closureVars` passed via `FCLOSURE` opcode |
| Constants | `JSValue[] constantPool` per function bytecode |
| Atoms | `String[] atomPool` for property names (interned) |
| Control flow | Absolute PC offsets via `IF_FALSE/IF_TRUE/GOTO` (32-bit signed) + 8/16-bit short forms |
| Exception handling | `JSCatchOffset` markers on value stack; unwinding pops until marker found |
| Generators | `StackFrame.programCounter` saved/restored on yield/resume |

### 1.2 Why the JVM is a Good JIT Target

1. **Stack-machine to stack-machine translation**: Both qjs4j and the JVM are stack-based. Many opcodes map almost 1:1 (push, pop, dup, swap, add, sub, goto, if_*).

2. **HotSpot optimizes the generated code further**: The JVM's C1/C2 JIT compilers inline method calls, eliminate dead code, hoist loop invariants, and allocate registers — all for free once we emit JVM bytecode.

3. **`invokedynamic` handles polymorphism**: The `invokedynamic` instruction (JSR 292) was designed exactly for this: dynamic dispatch with mutable call sites that can be relinked based on runtime type feedback. Nashorn proved this works for JavaScript.

4. **`MethodHandle` for fast native calls**: Property access helpers, type conversion, and built-in methods can be wired through `MethodHandle` chains, which HotSpot inlines aggressively.

5. **Good tooling options for bytecode generation**: Java 17+ includes `java.lang.invoke` (MethodHandles, CallSite, invokedynamic). For class generation, use either shaded ASM (recommended on Java 17) or the JDK Class-File API on Java 24+.

---

## 2. Global JIT Enable/Disable Flag

### 2.1 Design

A runtime-level flag controls whether the JIT compiler is active. When disabled, all functions execute through the interpreter unconditionally — no compilation is triggered and no compiled code is invoked.

```java
public final class JSRuntime {
    private volatile boolean jitEnabled = false; // off by default until stable
    private final AtomicLong jitEpoch = new AtomicLong(0);

    /** Enable or disable the JIT compiler globally. */
    public void setJitEnabled(boolean enabled) {
        this.jitEnabled = enabled;
        jitEpoch.incrementAndGet(); // invalidate compiled-entry eligibility
    }

    public boolean isJitEnabled() {
        return jitEnabled;
    }

    public long getJitEpoch() {
        return jitEpoch.get();
    }
}
```

### 2.2 Integration Points

The flag is checked at two points in the execution path:

**1. Compilation trigger** — `JSBytecodeFunction.call()` only considers JIT compilation when the flag is enabled:

```java
public JSValue call(JSContext context, JSValue thisArg, JSValue[] args) {
    boolean jitEnabled = context.getRuntime().isJitEnabled();

    // Fast path: use JIT-compiled code if available AND JIT is enabled
    MethodHandle jit = this.jitCompiledMethod;
    if (jitEnabled && jit != null && this.jitEpoch == context.getRuntime().getJitEpoch()) {
        return (JSValue) jit.invokeExact(context, thisArg, args, ...);
    }

    // Compilation trigger: only when JIT is enabled
    if (jitEnabled && ++callCount >= JIT_THRESHOLD && !jitCompilationRequested) {
        jitCompilationRequested = true;
        JITCompiler.enqueueCompilation(this);
    }

    // Interpreter fallback (always available)
    return context.getVirtualMachine().execute(this, thisArg, args);
}
```

**2. Runtime toggle** — Disabling JIT mid-execution takes effect on the next function entry. Functions currently running in JIT-compiled code complete their current invocation, but subsequent calls fall back to the interpreter because epoch checks fail until recompilation under the new epoch.

### 2.3 Use Cases

| Use Case | How |
|---|---|
| **Debugging** | Disable JIT to rule out JIT bugs; single-step through interpreter logic |
| **Differential testing** | Run test262 twice (JIT on vs. off), compare all results for equivalence |
| **Bug isolation** | If a test fails with JIT enabled but passes without, the bug is in the JIT compiler |
| **Benchmarking** | Measure interpreter-only vs. JIT-enabled to quantify JIT speedup |
| **CI/CD safety** | Run full test suite with JIT disabled as a regression gate |
| **Embedding** | Applications embedding qjs4j can disable JIT if they prefer predictable latency over peak throughput (no compilation pauses) |

### 2.4 CLI and Programmatic Access

The flag is controllable from both the Java API and the CLI interpreter:

```java
// Java API
JSRuntime runtime = new JSRuntime();
runtime.setJitEnabled(false);  // Interpreter-only mode
try (JSContext context = new JSContext(runtime)) {
    context.eval("...");  // Always interpreted
}
```

```bash
# CLI
java -jar qjs4j.jar --no-jit script.js    # Interpreter-only
java -jar qjs4j.jar script.js             # JIT enabled (default)
```

The `QuickJSInterpreter` main class parses `--no-jit` and calls `runtime.setJitEnabled(false)` before executing any scripts.

---

## 3. Translation Strategy

### 3.1 Core Approach: Method-at-a-Time Baseline JIT

Each `JSBytecodeFunction` is compiled to a single JVM class with one static method:

```java
// Generated JVM class for a JS function
public class JSFunc_$42 {
    public static JSValue execute(
        JSContext context,
        JSValue thisArg,
        JSValue[] args,
        JSValue[] locals,
        JSValue[] closureVars,
        JSValue[] constants,
        String[] atoms
    ) {
        // ... generated JVM bytecode ...
    }
}
```

The generated method replaces the interpreter loop for that function. The function's `call()` method checks: if JIT-compiled class exists and the runtime epoch matches, invoke it; otherwise, fall back to interpreter.

### 3.2 Opcode Translation Categories

#### Category A: Direct Translation (~80 opcodes)

These map almost 1:1 to JVM bytecode or trivial helper calls:

| qjs4j opcode | JVM translation |
|---|---|
| `PUSH_I32(value)` | `new JSNumber(value)` → `astore` to stack |
| `PUSH_0..7` | Load pre-cached `JSNumber` constant |
| `PUSH_TRUE/FALSE` | `getstatic JSBoolean.TRUE/FALSE` |
| `UNDEFINED/NULL` | `getstatic JSUndefined.INSTANCE / JSNull.INSTANCE` |
| `PUSH_CONST(idx)` | `aload constants; iconst idx; aaload` |
| `DUP` | `dup` |
| `DROP` | `pop` |
| `SWAP` | `swap` |
| `GET_LOCAL(idx)` / `GET_LOC0..3` | `aload locals; iconst idx; aaload` |
| `SET_LOCAL(idx)` / `SET_LOC0..3` | `aload locals; iconst idx; aload value; aastore` |
| `GET_ARG(idx)` / `GET_ARG0..3` | `aload args; iconst idx; aaload` |
| `GET_VAR_REF(idx)` | `aload closureVars; iconst idx; aaload` |
| `GOTO(offset)` | `goto label_target` |
| `IF_FALSE(offset)` | `invokestatic JSTypeConversions.toBoolean; ifeq label_target` |
| `IF_TRUE(offset)` | `invokestatic JSTypeConversions.toBoolean; ifne label_target` |
| `RETURN` | `areturn` |
| `RETURN_UNDEF` | `getstatic JSUndefined.INSTANCE; areturn` |
| `THROW` | `invokestatic throwHelper(context, value)` |

#### Category B: Helper Call Translation (~120 opcodes)

These require runtime type dispatch and are compiled as calls to static helper methods:

| qjs4j opcode | JVM translation |
|---|---|
| `ADD` | `invokestatic JITHelpers.add(context, left, right)` |
| `SUB/MUL/DIV/MOD` | `invokestatic JITHelpers.sub/mul/div/mod(...)` |
| `EQ/NEQ/LT/GT/...` | `invokestatic JITHelpers.eq/neq/lt/gt(...)` |
| `GET_FIELD(atom)` | `invokestatic JITHelpers.getField(context, obj, atoms[atomIdx])` |
| `PUT_FIELD(atom)` | `invokestatic JITHelpers.putField(context, obj, atoms[atomIdx], value)` |
| `GET_ARRAY_EL` | `invokestatic JITHelpers.getElement(context, obj, key)` |
| `CALL(argc)` | `invokestatic JITHelpers.call(context, func, thisArg, args)` |
| `INSTANCEOF` | `invokestatic JITHelpers.instanceOf(context, left, right)` |
| `TYPEOF` | `invokestatic JITHelpers.typeOf(value)` |
| `TO_OBJECT` | `invokestatic JITHelpers.toObject(context, value)` |

The `JITHelpers` class contains the same logic currently in `VirtualMachine`'s handler methods (e.g., `handleAdd()`, `handleGetField()`), but extracted as static methods with explicit parameters instead of implicit stack access.

#### Category C: Complex / Deferred (~60 opcodes)

These require special handling or are deferred to the interpreter:

| Feature | Opcodes | Strategy |
|---|---|---|
| Exception handling | `CATCH`, `THROW` | JVM try-catch blocks with `JSCatchOffset` → label mapping |
| Generators | `YIELD`, `INITIAL_YIELD` | **Deferred**: run in interpreter (state machine too complex for baseline JIT) |
| Async/await | `AWAIT`, `RETURN_ASYNC` | **Deferred**: interpreter handles promise wrapping |
| for-of/for-await-of | `FOR_OF_START/NEXT`, `FOR_AWAIT_OF_*` | Helper calls with iterator protocol |
| Dynamic code (`eval`, `Function`) | `EVAL`, `APPLY_EVAL` and helper call sites | **Barrier**: execute via interpreter path; compiled code may deopt before dynamic-code execution |
| `with` | `WITH_*` | **Deferred**: parser/runtime support is incomplete; keep interpreted-only when introduced |
| Spread / rest | `SPREAD_ARRAY`, `REST`, `APPLY` | Helper calls |
| Destructuring | `ARRAY_NEW`, `DEFINE_ARRAY_EL`, etc. | Helper calls |

### 3.3 Exception Handling Translation

qjs4j uses stack-based catch markers (`JSCatchOffset`). The JIT translates these to JVM exception tables:

```
qjs4j bytecode:             JVM bytecode:
  CATCH +offset    →        try {
    ...body...                  ...body...
  (exception)                } catch (JSVirtualMachineException e) {
                                 // convert to JS error value + preserve pending-exception contract
                                 aload e; invokevirtual getJsError;
                                 // materialize exception value in jitStack / context
                             }
```

The `CATCH` opcode pushes a `JSCatchOffset` on the stack. During JIT compilation, a **pre-pass** identifies catch marker lifetimes (`CATCH` to marker removal / frame exit) and builds equivalent JVM try-catch regions.

### 3.4 Control Flow Graph Construction

Before emitting JVM bytecode, the JIT must build a **control flow graph (CFG)** from the linear qjs4j bytecode:

1. **Identify basic block boundaries**: Targets of GOTO/IF_* instructions, exception handler entry points.
2. **Map qjs4j PC offsets → JVM labels**: Every branch target becomes a JVM `Label`.
3. **Stack depth analysis**: Verify stack balance at join points (needed for JVM verifier).
4. **Variable liveness**: Determine which locals are live at each point (for register allocation by HotSpot).

This requires explicit handling of variable-arity opcodes (for example `CALL`, `TAIL_CALL`, `EVAL`) where `nPop` is operand-dependent.

---

## 4. Type Specialization (Phase 2 Optimization)

### 4.1 The Polymorphism Problem

The baseline JIT emits generic helper calls for every operation: `JITHelpers.add(context, left, right)` checks types at runtime every time. For a hot loop like:

```javascript
for (let i = 0; i < 1000000; i++) { sum += arr[i]; }
```

Every `ADD` executes: `instanceof JSString` check → `instanceof JSNumber` check → unbox → double add → box to `new JSNumber()`. This is wasteful because `i` and `arr[i]` are always numbers.

### 4.2 `invokedynamic` + Inline Caches

The solution is `invokedynamic` with **polymorphic inline caches (PICs)**:

```java
// Instead of: invokestatic JITHelpers.add(context, left, right)
// Emit:       invokedynamic add(JSValue, JSValue)JSValue [bootstrap=JITBootstrap.add]
```

The bootstrap method returns a `CallSite` that starts **uninitialized**, then on first call:

1. Checks actual types (e.g., both `JSNumber`)
2. Links a fast path: `MethodHandle` that unboxes doubles, adds, re-boxes
3. Installs a guard: `if (left instanceof JSNumber && right instanceof JSNumber)` → fast path, else → slow path that relinks

This is exactly how Nashorn implemented JavaScript arithmetic on the JVM.

### 4.3 Type Profiling for Speculative Optimization

Add lightweight **type profiling** to the interpreter:

```java
// In VirtualMachine.handleAdd():
typeProfile[pc] = TypeProfile.record(left.getClass(), right.getClass());
```

When the JIT compiles a function, it reads the type profile and emits **speculative fast paths** guarded by type checks:

```java
// JIT-generated code for ADD at a profiled site:
if (left instanceof JSNumber l && right instanceof JSNumber r) {
    push(new JSNumber(l.value() + r.value()));  // Fast path
} else {
    push(JITHelpers.addSlow(context, left, right));  // Deopt path
}
```

HotSpot will further optimize the fast path branch (inline, eliminate boxing via escape analysis).

### 4.4 On-Stack Replacement (OSR)

For long-running loops, the interpreter should be able to transfer execution mid-function to JIT-compiled code:

1. At loop back-edges, increment a **counter**.
2. When counter exceeds threshold, **trigger JIT compilation** of the function.
3. Build a JVM stack frame from the interpreter's current `StackFrame` state.
4. Jump into the JIT-compiled code at the loop header.

OSR is complex but critical for benchmarks and real-world workloads with hot inner loops.

---

## 5. Implementation Plan

### Phase 0: Foundation (Prerequisite Refactoring)

**Goal**: Extract interpreter logic into reusable static helpers and add the JIT control infrastructure.

1. **Add global JIT controls to `JSRuntime`** — `volatile boolean jitEnabled` plus `jitEpoch` (`AtomicLong`) with `setJitEnabled(boolean)` / `isJitEnabled()` / `getJitEpoch()`. Add `--no-jit` CLI flag to `QuickJSInterpreter`. This is the first deliverable because all subsequent JIT code is gated behind this flag.

2. **Create `JITHelpers.java` and a shared invocation gateway** — Extract the ~40 `handle*()` methods from `VirtualMachine.java` into public static methods and route calls through a single helper:
   - `JSValue add(JSContext ctx, JSValue left, JSValue right)`
   - `JSValue getField(JSContext ctx, JSValue obj, String fieldName)`
   - `JSValue invokeFunction(JSContext ctx, JSValue func, JSValue thisArg, JSValue[] args)` (used by both interpreter and JIT)
   - etc.
   - This gateway is also where dynamic-code barriers are enforced (`eval()` / `Function()` / interpreted-only callees).

3. **Add `Bytecode.getInstructionOffsets()`** — Pre-compute all valid instruction start offsets for CFG construction.

4. **Add type profile slots** to `Bytecode` — `int[] typeProfileData` indexed by PC, recording observed types at key operations. Type profiling is only active when `runtime.isJitEnabled()` is true — no overhead in interpreter-only mode.

5. **Add JIT compilation fields** to `JSBytecodeFunction` — `volatile MethodHandle jitCompiledMethod`, `int callCount`, and `long jitEpoch`. The `call()` method checks both `runtime.isJitEnabled()` and epoch match before entering JIT code (see Section 2.2).

**Estimated scope**: ~900 lines of refactoring, no behavioral changes.

### Phase 1: Baseline JIT Compiler

**Goal**: Compile any `JSBytecodeFunction` to a JVM class that produces identical results to the interpreter.

#### 1.1 Add ASM Dependency

```kotlin
// build.gradle.kts (jit module or shaded internal dependency)
implementation("org.ow2.asm:asm:9.7.1")
implementation("org.ow2.asm:asm-commons:9.7.1")
```

If zero-runtime-dependency policy remains strict, shade ASM into an internal package or keep JIT in an optional artifact. Alternatively, on Java 24+, use the built-in Class-File API (JEP 484).

#### 1.2 Implement `JITCompiler.java`

Core class with method:
```java
public class JITCompiler {
    /**
     * Compile a JS bytecode function to a JVM class.
     * Returns a MethodHandle to the generated execute() method.
     */
    public MethodHandle compile(JSBytecodeFunction function) { ... }
}
```

Internal steps:
1. **CFG construction**: Scan qjs4j bytecode to identify basic blocks and branch targets.
2. **Stack analysis**: Compute stack depth at each instruction for JVM verifier.
3. **Exception region mapping**: Convert CATCH stack markers to JVM exception table entries.
4. **Opcode translation**: Walk bytecode linearly, emitting JVM bytecode per opcode.
5. **Class loading**: Use `MethodHandles.Lookup.defineHiddenClass()` (Java 15+) to load the generated class without polluting the classloader namespace.

#### 1.3 Opcode Translation Engine

```java
class OpcodeTranslator {
    void translate(Opcode op, int pc, Bytecode bytecode, MethodVisitor mv) {
        switch (op) {
            case PUSH_I32 -> {
                int value = bytecode.readI32(pc + 1);
                // Emit: new JSNumber(value)
                mv.visitTypeInsn(NEW, "com/caoccao/qjs4j/core/JSNumber");
                mv.visitInsn(DUP);
                mv.visitLdcInsn((double) value);
                mv.visitMethodInsn(INVOKESPECIAL, "com/caoccao/qjs4j/core/JSNumber", "<init>", "(D)V", false);
            }
            case ADD -> {
                // Emit: invokestatic JITHelpers.add(context, right, left)
                // (stack has: ... left right → need to load context first)
                mv.visitVarInsn(ALOAD, 0); // context
                mv.visitInsn(SWAP);        // context left right → context right left...
                // Actually need careful stack manipulation — see section 4.4
                mv.visitMethodInsn(INVOKESTATIC, "JITHelpers", "add",
                    "(LJSContext;LJSValue;LJSValue;)LJSValue;", false);
            }
            case GET_LOCAL -> {
                int idx = bytecode.readU16(pc + 1);
                mv.visitVarInsn(ALOAD, LOCALS_SLOT); // locals array
                mv.visitLdcInsn(idx);
                mv.visitInsn(AALOAD);
            }
            // ... 262 cases total
        }
    }
}
```

#### 1.4 Stack Mapping Strategy

Do **not** mirror the qjs4j value stack directly onto the JVM operand stack. Instead, use an explicit `JSValue[] jitStack` + `int sp` in generated code.

Rationale:
- The JVM operand stack is difficult to keep verifier-correct across complex branch merges.
- qjs4j stack can contain internal markers (`JSCatchOffset`, internal iterator state), which should stay in explicit runtime state.
- Explicit stack state simplifies deoptimization and OSR handoff.

The JVM operand stack is then used only for temporary values and helper-call arguments.

#### 1.5 Exception Handling Translation

Pre-pass to build exception regions:

```java
// Phase 1: Scan bytecode for CATCH opcodes
Map<Integer, Integer> catchRegions = new HashMap<>();  // CATCH_pc → handler_pc
for (int pc = 0; pc < bytecodeLength; ) {
    Opcode op = readOpcode(pc);
    if (op == Opcode.CATCH) {
        int offset = bytecode.readI32(pc + 1);
        int handlerPC = pc + op.getSize() + offset;
        catchRegions.put(pc, handlerPC);
    }
    pc += op.getSize();
}

// Phase 2: Emit JVM try-catch blocks
for (var entry : catchRegions.entrySet()) {
    Label tryStart = labelForPC(entry.getKey() + opSize);
    Label tryEnd = findMatchingEndLabel(entry.getKey());
    Label handler = labelForPC(entry.getValue());
    mv.visitTryCatchBlock(tryStart, tryEnd, handler, "JSVirtualMachineException");
}
```

#### 1.6 Generator / Async Bailout

Functions with `isGenerator=true` or `isAsync=true` are **not JIT-compiled** in Phase 1. They remain interpreted. The `YIELD` and `AWAIT` opcodes require coroutine-like state saving that doesn't map naturally to JVM bytecode without continuation support.

Future: Java's Project Loom virtual threads or explicit state-machine transformation could enable this.

#### 1.7 `eval()` and `Function()` Handling

Phase 1 rules:
- `GlobalObject.eval()` and `FunctionConstructor.call()` continue to compile source text via existing compiler pipeline.
- Newly created functions start in interpreter mode and are JIT-eligible only after normal hotness thresholds.
- Compiled callers treat dynamic-code operations as deopt barriers: no assumption that lexical bindings or global object state remain unchanged across the call.
- If bytecode ever emits `EVAL` / `APPLY_EVAL` directly, mark the containing function interpreted-only until explicit direct-eval scope materialization exists.

#### 1.8 Compilation Trigger

**Counter-based tiered compilation** gated by the global JIT flag (see Section 2.2 for the full dispatch logic):

- Every function call increments `JSBytecodeFunction.callCount` only when `runtime.isJitEnabled()` is true.
- Only non-async, non-generator bytecode functions participate in Phase 1 JIT thresholds.
- At threshold (e.g., 1000 calls), trigger background JIT compilation.
- Until compilation finishes, continue interpreting.
- Once compiled, atomically swap in the `MethodHandle`.
- When `runtime.isJitEnabled()` is false, the `callCount` check and `jitCompiledMethod` dispatch are both skipped — zero JIT overhead.

**Estimated scope**: ~2,500 lines for the baseline JIT compiler + ~600 lines for helper extraction.

### Phase 2: Type Specialization

**Goal**: Optimize hot paths with inline caches and type guards.

1. **Add type profiling** to interpreter (~200 lines):
   - Record operand types at ADD, SUB, MUL, GET_FIELD, CALL sites.
   - Store in per-function `TypeProfile[]` array indexed by PC.

2. **Speculative compilation** (~800 lines):
   - Read type profile during JIT.
   - For monomorphic sites (same types every time), emit guarded fast paths.
   - For megamorphic sites (many types), emit generic helper calls.

3. **`invokedynamic` call sites** (~500 lines):
   - Replace `invokestatic JITHelpers.add(...)` with `invokedynamic` at profiled sites.
   - Bootstrap methods link to type-specialized `MethodHandle` chains.
   - Support relinking on type mismatch (polymorphic inline caches).

4. **Deoptimization** (~400 lines):
   - When a type guard fails, invalidate the JIT-compiled code.
   - Fall back to interpreter, re-profile, recompile.
   - Use `SwitchPoint` from `java.lang.invoke` for efficient invalidation.

**Estimated scope**: ~1,900 lines.

### Phase 3: On-Stack Replacement (OSR)

**Goal**: Transfer execution from interpreter to JIT-compiled code mid-function at loop back-edges.

1. **Loop detection** in bytecode: Identify back-edges (GOTO with negative offset).
2. **OSR entry points**: Generate special entry stubs in JIT-compiled code that accept interpreter state (locals, stack values, PC).
3. **State transfer**: Marshal `StackFrame.locals[]` + `CallStack` values into JIT method parameters.
4. **Counter at back-edges**: Interpreter checks counter at every loop back-edge.

**Estimated scope**: ~1,200 lines. This is the most complex phase.

### Phase 4: Advanced Optimizations (Future)

- **Escape analysis hints**: Mark `new JSNumber()` as non-escaping so HotSpot can stack-allocate or scalar-replace them.
- **Constant folding**: Pre-evaluate operations on constants during JIT compilation.
- **Inlining**: Inline small called functions into the caller's JIT-compiled code.
- **Generator state machine**: Transform YIELD-based generators into explicit state machines compilable to JVM bytecode.

---

## 6. Challenges and Mitigations

### 6.1 Dynamic Code: `eval()`, `Function()`, and `with`

**Problem**:
- `eval()` can execute source text at runtime and may depend on caller strictness/scope.
- `Function()` compiles source text at runtime and returns a new callable.
- `with` introduces dynamic name resolution.

**Mitigation**:
- Treat dynamic-code operations as **JIT barriers** in Phase 1.
- For `GlobalObject.eval()` and `FunctionConstructor.call()`, execute through interpreter/compile pipeline exactly as today, then return to compiled caller.
- Any function that uses direct-eval semantics (when `EVAL`/`APPLY_EVAL` is active in bytecode) is interpreted-only until explicit deopt+reentry support exists.
- `with` remains interpreted-only (and currently parser/runtime support is incomplete).

### 6.2 JIT/Interpreter Interaction Contract

**Problem**: Mixed-mode execution (JIT caller → interpreted callee, interpreted caller → JIT callee, native calls, exception propagation) can diverge from interpreter semantics if there are multiple call paths.

**Mitigation**:
- Introduce one shared invocation gateway used by both interpreter and JIT-generated code:
  - `invokeFunction(context, function, thisArg, args)`
  - decides native vs bytecode call, JIT eligibility, and epoch checks
- Keep pending-exception behavior identical to interpreter:
  - helpers must set/clear context pending exceptions exactly as existing VM logic expects
  - thrown `JSVirtualMachineException` must map to the same observable JS errors
- Generators/async functions stay interpreted in Phase 1, but can still be called from JIT code through the same gateway.

### 6.3 Proxy Objects

**Problem**: `Proxy` traps can intercept any property access or function call, executing arbitrary JavaScript.

**Mitigation**: All property access goes through helper methods (`JITHelpers.getField()`) that check for Proxy objects. The fast path (non-Proxy) is optimized; the slow path calls the trap. With type profiling, if a call site never sees a Proxy, the JIT can emit a guarded fast path that deoptimizes if a Proxy appears.

### 6.4 Exception Handling Overhead

**Problem**: The interpreter checks `pendingException` after every opcode. Generating an explicit check after every JVM instruction would be prohibitively expensive.

**Mitigation**: Helper methods throw `JSVirtualMachineException` (a Java exception) on error. The JVM's exception mechanism handles propagation to the nearest catch block. This eliminates per-opcode checks — the JVM's zero-cost exception handling takes over.

This is actually a **performance win** over the interpreter, which pays the cost of the `pendingException != null` check on every iteration.

### 6.5 Stack Value Stack vs. JVM Operand Stack

**Problem**: qjs4j's `CallStack` can hold both `JSValue` and `JSCatchOffset` (exception handler markers). The JVM operand stack is statically typed.

**Mitigation**: In JIT-compiled code, use explicit stack state (`JSValue[] jitStack`, `int sp`) and keep internal markers in structured runtime state instead of JVM stack values. `JSCatchOffset` behavior is represented through exception table regions plus explicit handler metadata.

### 6.6 Zero External Dependencies Constraint

**Problem**: qjs4j's design principle is "zero external dependencies." ASM would violate this.

**Mitigation options**:
- **Option A**: Shade ASM into the qjs4j jar (rename package to `com.caoccao.qjs4j.internal.asm`). No runtime dependency visible to users.
- **Option B**: Use the JDK Class-File API (JEP 484, finalized in Java 24). Requires bumping the minimum Java version from 17 to 24.
- **Option C**: Hand-write JVM class file bytes directly (`.class` format is well-documented). This avoids all dependencies but is error-prone and difficult to maintain.
- **Option D (Recommended)**: Shade ASM. It's ~400KB, no transitive dependencies, and battle-tested. The Kotlin compiler, Gradle, Spring, and Hibernate all shade ASM internally.

### 6.7 JVM Verifier Constraints

**Problem**: The JVM bytecode verifier requires correct `StackMapTable` frames at branch targets and exception handlers. Getting these wrong causes `VerifyError` at class load time.

**Mitigation**: Use ASM's `ClassWriter(COMPUTE_FRAMES)` mode, which automatically computes correct stack map frames. This adds a small compilation overhead but eliminates an entire class of bugs.

---

## 7. Performance Expectations

### 7.1 Baseline JIT (Phase 1)

Expected speedup: **2–5x** over the interpreter for compute-bound code.

- Eliminates switch-dispatch overhead (~15% of interpreter time).
- Eliminates per-opcode `pendingException` check (~5–10% of interpreter time).
- HotSpot inlines small helper methods (e.g., `JSNumber` unboxing).
- HotSpot's register allocator replaces stack loads/stores with register accesses.
- Constant pool lookups become direct `ldc` constants.

### 7.2 Type-Specialized JIT (Phase 2)

Expected speedup: **5–20x** over the interpreter for numeric-heavy code.

- Eliminates `instanceof` type checks on hot paths.
- Enables HotSpot escape analysis to eliminate `new JSNumber()` boxing.
- `invokedynamic` call sites inline to direct method calls.
- Property access with stable shapes inlines to direct field offset loads.

### 7.3 Comparison with Existing Engines

| Engine | Approach | Typical Performance |
|---|---|---|
| QuickJS (C) | Interpreter only | 1x (baseline) |
| qjs4j interpreter | Java switch-dispatch | ~0.3–0.5x of QuickJS C (JVM overhead) |
| qjs4j + baseline JIT | JVM bytecode, generic helpers | ~1–2x of QuickJS C |
| qjs4j + type-spec JIT | invokedynamic + inline caches | ~3–10x of QuickJS C |
| Nashorn (deprecated) | Full invokedynamic JIT | ~5–15x of QuickJS C |
| GraalJS + Graal JIT | Truffle partial evaluation | ~20–50x of QuickJS C |
| V8 | TurboFan optimizing JIT | ~50–100x of QuickJS C |

---

## 8. File and Package Structure

```
com.caoccao.qjs4j/
├── jit/
│   ├── JITCompiler.java          # Main JIT compilation entry point
│   ├── JITHelpers.java           # Static helper methods called by generated code
│   ├── OpcodeTranslator.java     # qjs4j opcode → JVM bytecode translation
│   ├── CFGBuilder.java           # Control flow graph construction
│   ├── ExceptionRegionMapper.java # CATCH markers → JVM exception tables
│   ├── StackAnalyzer.java        # Stack depth verification for JVM verifier
│   ├── TypeProfile.java          # Per-site type profiling data
│   ├── JITClassLoader.java       # Hidden class loading via MethodHandles.Lookup
│   └── InlineCacheBootstrap.java # invokedynamic bootstrap methods (Phase 2)
├── vm/
│   ├── VirtualMachine.java       # Refactored to use JITHelpers (Phase 0)
│   ├── Opcode.java               # Unchanged
│   ├── Bytecode.java             # + getInstructionOffsets(), type profile slots
│   ├── StackFrame.java           # Unchanged
│   └── CallStack.java            # Unchanged
├── core/
│   ├── JSRuntime.java            # + jitEnabled flag, setJitEnabled(), invalidateAllJitCode()
│   └── JSBytecodeFunction.java   # + jitCompiledMethod, callCount, compilation trigger
└── cli/
    └── QuickJSInterpreter.java   # + --no-jit argument parsing
```

---

## 9. Testing Strategy

The global JIT flag (Section 2) is the backbone of the testing strategy. It enables systematic comparison between interpreter and JIT execution paths.

1. **Differential testing via the global flag**: Run the entire test262 suite twice — once with `runtime.setJitEnabled(false)` (interpreter-only) and once with `runtime.setJitEnabled(true)` (JIT active). All results must be identical. Any divergence is a JIT compiler bug. This can be automated as a single Gradle task:
   ```
   ./gradlew test262 -PjitEnabled=false    # Baseline: interpreter-only
   ./gradlew test262 -PjitEnabled=true     # Compare: JIT-enabled
   ```

2. **CI/CD dual-mode gate**: The CI pipeline runs the full unit test suite in both modes. A test that passes with `--no-jit` but fails without it is flagged as a JIT regression. A test that fails in both modes is an interpreter bug unrelated to JIT.

3. **JIT-specific unit tests**: Test each opcode translation in isolation. Create minimal functions that exercise one opcode category, compile via JIT, execute, compare results against interpreter output.

4. **Deoptimization tests**: Functions that start with one type profile then encounter a different type. Verify correct fallback and recompilation. Toggle the global flag mid-execution to verify that `invalidateAllJitCode()` correctly discards compiled code and subsequent calls use the interpreter.

5. **JVM verifier validation**: Every generated class must load without `VerifyError`. The test suite catches this automatically.

6. **Benchmark suite**: JMH benchmarks comparing interpreter (`--no-jit`) vs. JIT-enabled on:
   - Arithmetic-heavy loops (fibonacci, mandelbrot)
   - Property access patterns (object traversal)
   - String operations
   - Mixed workloads (test262 full suite timing)
   - The global flag makes A/B comparison trivial — same binary, different flag.

7. **Dynamic-code interaction tests**:
   - JIT-compiled caller invoking `eval()` and `Function()`
   - functions produced by `eval()`/`Function()` crossing thresholds and becoming JIT-compiled
   - runtime toggle (`setJitEnabled(false/true)`) before and after dynamic-code creation
   - equivalence checks for exception propagation and pending-exception state in mixed JIT/interpreter stacks

---

## 10. Milestone Summary

| Phase | Scope | Deliverable |
|---|---|---|
| **Phase 0** | Foundation | Global JIT flag on `JSRuntime` + `--no-jit` CLI, `JITHelpers.java`, type profile slots, `jitCompiledMethod` field |
| **Phase 1** | Baseline JIT | Method-at-a-time compiler, 262 opcode translations, exception handling, generator bailout |
| **Phase 2** | Type specialization | `invokedynamic` inline caches, type profiling, speculative optimization, deoptimization |
| **Phase 3** | OSR | Mid-function interpreter → JIT transfer at loop back-edges |
| **Phase 4** | Advanced | Escape analysis hints, function inlining, generator state machines |

---

## 11. Conclusion

Adding a JIT compiler to qjs4j is **technically feasible** and would provide significant performance improvements. The stack-based architecture of both qjs4j and the JVM makes bytecode translation natural. The main implementation effort is in the baseline compiler (~3,300 lines), with type specialization (~1,900 lines) and OSR (~1,200 lines) as follow-on phases.

The recommended approach is:
1. Start with Phase 0 (refactoring) to establish the helper method layer.
2. Implement Phase 1 (baseline JIT) targeting the ~200 non-generator, non-async opcodes.
3. Validate correctness against the test262 suite before proceeding to optimizations.
4. Add Phase 2 (type specialization with invokedynamic) for hot numeric paths.

The zero-dependency constraint can be satisfied by shading ASM or waiting for JDK 24+ to use the built-in Class-File API. The Nashorn project demonstrated that this approach (JavaScript → JVM bytecode via invokedynamic) yields competitive performance on the JVM, and qjs4j is well-positioned to follow the same path.
